{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class SimpleCNNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNNNet, self).__init__()\n",
    "        # Convolutional Layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)\n",
    "        # Dropout Layer: 30% der Neuronen werden zufällig \"ausgeschaltet\"\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        # Hidden Layer - Anzahl der Neuronen: (I - K + 1)^2 * F / 2*P\n",
    "        # I = 28: Bild mit 28x28 Pixel\n",
    "        # K = 3: Kernel Größe\n",
    "        # F = 16: Anzahl der Filter\n",
    "        # P = 2: Pooling Operation1\n",
    "        self.hidden_layer = nn.Linear(2704, 128) \n",
    "        self.output_layer = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x , (2,2))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    \"../mnist_data\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()]),\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataset = datasets.MNIST(\n",
    "    \"../mnist_data\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transforms.Compose([transforms.ToTensor()]),\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset) + len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\" \n",
    "model = SimpleCNNNet().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 100, Average Loss: 2.130849679708481\n",
      "Epoch: 0, Batch: 200, Average Loss: 1.8365431880950929\n",
      "Epoch: 0, Batch: 300, Average Loss: 1.525294956366221\n",
      "Epoch: 0, Batch: 400, Average Loss: 1.2994868168234825\n",
      "Epoch: 0, Batch: 500, Average Loss: 1.143743477702141\n",
      "Epoch: 0, Batch: 600, Average Loss: 1.030202533081174\n",
      "Epoch: 0, Batch: 700, Average Loss: 0.9449341111736638\n",
      "Epoch: 0, Batch: 800, Average Loss: 0.8754402166232467\n",
      "Epoch: 0, Batch: 900, Average Loss: 0.8214053858816623\n",
      "Epoch: 1, Batch: 100, Average Loss: 0.36910633444786073\n",
      "Epoch: 1, Batch: 200, Average Loss: 0.3710865820944309\n",
      "Epoch: 1, Batch: 300, Average Loss: 0.36160923798878986\n",
      "Epoch: 1, Batch: 400, Average Loss: 0.35808429021388294\n",
      "Epoch: 1, Batch: 500, Average Loss: 0.3568768500983715\n",
      "Epoch: 1, Batch: 600, Average Loss: 0.35514166614661613\n",
      "Epoch: 1, Batch: 700, Average Loss: 0.3541108517668077\n",
      "Epoch: 1, Batch: 800, Average Loss: 0.3505493401456624\n",
      "Epoch: 1, Batch: 900, Average Loss: 0.3470132754991452\n",
      "Epoch: 2, Batch: 100, Average Loss: 0.3246380853652954\n",
      "Epoch: 2, Batch: 200, Average Loss: 0.3243110801279545\n",
      "Epoch: 2, Batch: 300, Average Loss: 0.3181077188253403\n",
      "Epoch: 2, Batch: 400, Average Loss: 0.31413923172280195\n",
      "Epoch: 2, Batch: 500, Average Loss: 0.31271635337173936\n",
      "Epoch: 2, Batch: 600, Average Loss: 0.31115955583751204\n",
      "Epoch: 2, Batch: 700, Average Loss: 0.3113491441628763\n",
      "Epoch: 2, Batch: 800, Average Loss: 0.3098865361418575\n",
      "Epoch: 2, Batch: 900, Average Loss: 0.30747319092353187\n",
      "Epoch: 3, Batch: 100, Average Loss: 0.28615674808621405\n",
      "Epoch: 3, Batch: 200, Average Loss: 0.2925735427811742\n",
      "Epoch: 3, Batch: 300, Average Loss: 0.29300705234209695\n",
      "Epoch: 3, Batch: 400, Average Loss: 0.29070527423173187\n",
      "Epoch: 3, Batch: 500, Average Loss: 0.2891175633817911\n",
      "Epoch: 3, Batch: 600, Average Loss: 0.28597124385337036\n",
      "Epoch: 3, Batch: 700, Average Loss: 0.28616489479584356\n",
      "Epoch: 3, Batch: 800, Average Loss: 0.2855516780726612\n",
      "Epoch: 3, Batch: 900, Average Loss: 0.2861775301893552\n",
      "Epoch: 4, Batch: 100, Average Loss: 0.25255362823605537\n",
      "Epoch: 4, Batch: 200, Average Loss: 0.2540854778140783\n",
      "Epoch: 4, Batch: 300, Average Loss: 0.2575508408496777\n",
      "Epoch: 4, Batch: 400, Average Loss: 0.2662674374692142\n",
      "Epoch: 4, Batch: 500, Average Loss: 0.2676826134324074\n",
      "Epoch: 4, Batch: 600, Average Loss: 0.2686859745035569\n",
      "Epoch: 4, Batch: 700, Average Loss: 0.2677050858097417\n",
      "Epoch: 4, Batch: 800, Average Loss: 0.26744059659540653\n",
      "Epoch: 4, Batch: 900, Average Loss: 0.26618255525827406\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, optimizer, loss_function, device=\"cpu\", epochs=5):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(data)\n",
    "            batch_loss = loss_function(predictions, target)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += batch_loss.item()\n",
    "            if (batch_idx+1) % 100 == 0:\n",
    "                print(f\"Epoch: {epoch}, Batch: {batch_idx+1}, Average Loss: {running_loss/(batch_idx + 1)}\")\n",
    "train(model, train_loader, optimizer, loss_function, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.2286, Accuracy: 9339/10000 (93.390%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test(model, test_loader, loss_function, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    batch_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            predictions = model(data)\n",
    "            batch_loss += loss_function(predictions, target).item()\n",
    "            predicted_labels = predictions.argmax(dim=1, keepdim=True)\n",
    "            correct += predicted_labels.eq(target.view_as(predicted_labels)).sum().item()\n",
    "    average_loss = batch_loss / len(test_loader)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f'Average loss: {average_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.3f}%)\\n')\n",
    "test(model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fruit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models, transforms, datasets\n",
    "fruit_model = models.resnet18(pretrained=True)\n",
    "number_features = fruit_model.fc.in_features\n",
    "for param in fruit_model.parameters():\n",
    "    param.requires_grad = False\n",
    "fruit_model.fc = nn.Linear(number_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "image_dataset = datasets.ImageFolder(\"data\", data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(image_dataset))\n",
    "test_size = len(image_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(image_dataset, [train_size, test_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                               batch_size=32,\n",
    "                                             shuffle=True, \n",
    "                                               num_workers=4)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                               batch_size=32,\n",
    "                                             shuffle=True, \n",
    "                                               num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(fruit_model.parameters(), lr=0.01)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "train(fruit_model, train_loader, optimizer, loss_function, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.3163, Accuracy: 121/128 (94.531%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(fruit_model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7438, 0.0643, 0.0832, 0.0971, 0.0117]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "def predict(model, tranform_function, image_path):\n",
    "    image = Image.open(image_path)\n",
    "    transformed = tranform_function(image).float().unsqueeze(0)\n",
    "    predicted = model(transformed)\n",
    "    probabilities = F.softmax(predicted, dim=1)\n",
    "    return probabilities\n",
    "predict(fruit_model, data_transform, \"evaluation/apple.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orange Probabilities: tensor([[0.7438, 0.0643, 0.0832, 0.0971, 0.0117]], grad_fn=<SoftmaxBackward>)\n",
      "Orange Probabilities: tensor([[0.0485, 0.8450, 0.0239, 0.0554, 0.0273]], grad_fn=<SoftmaxBackward>)\n",
      "Orange Probabilities: tensor([[0.2148, 0.0457, 0.0173, 0.6945, 0.0277]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "apple = \"evaluation/apple.jpg\"\n",
    "print(f\"Orange Probabilities: {predict(fruit_model, data_transform, apple)}\")\n",
    "banana = \"evaluation/banana.jpg\"\n",
    "print(f\"Orange Probabilities: {predict(fruit_model, data_transform, banana)}\")\n",
    "orange = \"evaluation/orange.jpg\"\n",
    "print(f\"Orange Probabilities: {predict(fruit_model, data_transform, orange)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(fruit_model.state_dict(), \"fruit_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "example_input = torch.rand(1, 3, 224, 224)\n",
    "traced_script_module = torch.jit.trace(fruit_model, example_input)\n",
    "traced_script_module.save(\"fruit_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!torch-model-archiver --model-name fruit_model --version 1.0 --serialized-file fruit_model.pt --extra-files index_to_name.json --handler image_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv fruit_model.mar models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchserve --start --ncs --model-store models --models fruit_model.mar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "  {\r\n",
      "    \"strawberry\": 0.9564064145088196\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"apple\": 0.02362699992954731\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"orange\": 0.010261671617627144\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"grape\": 0.006195542402565479\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"banana\": 0.003509427886456251\r\n",
      "  }\r\n",
      "]"
     ]
    }
   ],
   "source": [
    "!curl -X POST http://127.0.0.1:8080/predictions/fruit_model -T data/strawberry/00000001.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
